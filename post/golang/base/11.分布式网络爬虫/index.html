<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>[golang base(十一) | 分布式网络爬虫] - FaceDamon`s Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="facedamon" /><meta name="description" content="原因 有一定的复杂性 可以灵活调整项目的复杂性 平衡语言/爬虫之间的比重 爬虫分类 通用爬虫，如baidu，google 聚焦爬虫，从互联网获取结构化数" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.81.0 with theme even" />


<link rel="canonical" href="http://facedamon.github.io/post/golang/base/11.%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="[golang base(十一) | 分布式网络爬虫]" />
<meta property="og:description" content="原因 有一定的复杂性 可以灵活调整项目的复杂性 平衡语言/爬虫之间的比重 爬虫分类 通用爬虫，如baidu，google 聚焦爬虫，从互联网获取结构化数" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://facedamon.github.io/post/golang/base/11.%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2020-03-06T17:08:56&#43;08:00" />
<meta property="article:modified_time" content="2020-03-06T17:08:56&#43;08:00" />

<meta itemprop="name" content="[golang base(十一) | 分布式网络爬虫]">
<meta itemprop="description" content="原因 有一定的复杂性 可以灵活调整项目的复杂性 平衡语言/爬虫之间的比重 爬虫分类 通用爬虫，如baidu，google 聚焦爬虫，从互联网获取结构化数"><meta itemprop="datePublished" content="2020-03-06T17:08:56&#43;08:00" />
<meta itemprop="dateModified" content="2020-03-06T17:08:56&#43;08:00" />
<meta itemprop="wordCount" content="4383">
<meta itemprop="keywords" content="golang,未完待续," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[golang base(十一) | 分布式网络爬虫]"/>
<meta name="twitter:description" content="原因 有一定的复杂性 可以灵活调整项目的复杂性 平衡语言/爬虫之间的比重 爬虫分类 通用爬虫，如baidu，google 聚焦爬虫，从互联网获取结构化数"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">FaceDamon</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about-me/">
        <li class="mobile-menu-item">About Me</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">FaceDamon</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about-me/">About Me</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">[golang base(十一) | 分布式网络爬虫]</h1>

      <div class="post-meta">
        <span class="post-time"> 2020-03-06 </span>
        <div class="post-category">
            <a href="/categories/golang/base/"> golang/base </a>
            </div>
          <span class="more-meta"> 约 4383 字 </span>
          <span class="more-meta"> 预计阅读 9 分钟 </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次阅读 </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#如何发现用户">如何发现用户</a></li>
  </ul>

  <ul>
    <li><a href="#获取城市列表">获取城市列表</a>
      <ul>
        <li><a href="#正则表达式">正则表达式</a></li>
      </ul>
    </li>
    <li><a href="#继续">继续</a></li>
    <li><a href="#抽象解析器">抽象解析器</a></li>
    <li><a href="#抽象架构">抽象架构</a></li>
    <li><a href="#城市解析器">城市解析器</a></li>
    <li><a href="#用户解析器">用户解析器</a></li>
  </ul>

  <ul>
    <li><a href="#并发结构">并发结构</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h1 id="原因">原因</h1>
<ul>
<li>有一定的复杂性</li>
<li>可以灵活调整项目的复杂性</li>
<li>平衡语言/爬虫之间的比重</li>
</ul>
<h1 id="爬虫分类">爬虫分类</h1>
<ul>
<li>通用爬虫，如baidu，google</li>
<li>聚焦爬虫，从互联网获取结构化数据</li>
</ul>
<h1 id="总体结构">总体结构</h1>
<p><img src="https://cdn.jsdelivr.net/gh/facedamon/MarkDownPhotos@master/golang/crawler.png" alt="avatar"></p>
<h1 id="golang的库框架">golang的库/框架</h1>
<ul>
<li>henrylee2cn/pholcus</li>
<li>colly</li>
<li>gocrawl</li>
<li>hu17889/go_spider</li>
</ul>
<blockquote>
<p>将不使用现成的库/框架</p>
</blockquote>
<blockquote>
<p>使用ElasticSearch作为数据存储</p>
</blockquote>
<blockquote>
<p>使用Go标准模板库实现http数据展示</p>
</blockquote>
<h1 id="爬虫主题">爬虫主题</h1>
<ul>
<li>内容： 如新闻，博客，社区。。。</li>
<li>人：QQ空间，人人网，微博，微信，facebook？比较难
<ul>
<li>相亲网站，求职网站？静态简单，切忌隐私数据</li>
</ul>
</li>
</ul>
<h1 id="尝试人工获取内容">尝试人工获取内容</h1>
<p>  target: <a href="http://www.zhenai.com/zhenghun">珍爱网</a>，因为该网站的隐私数据相对求职网站较少，并且目录很明显.对于翻页操作也很方便，直接反应在了url上，还有“猜你喜欢”可以连接跳转，但是需要处理闭环问题，重复的人比较多。每个用户主页的url都自带了有顺序的id，这也很有帮助</p>
<h2 id="如何发现用户">如何发现用户</h2>
<ul>
<li>通过城市列表-&gt;城市-&gt;(下一页)-&gt;用户</li>
<li>通过用户-&gt;猜你喜欢</li>
<li>通过已有用户id+1来猜测用户id</li>
</ul>
<h1 id="爬虫总体算法">爬虫总体算法</h1>
<p><img src="https://cdn.jsdelivr.net/gh/facedamon/MarkDownPhotos@master/golang/city.png" alt="avatar"></p>
<h1 id="步骤">步骤</h1>
<p><img src="https://cdn.jsdelivr.net/gh/facedamon/MarkDownPhotos@master/golang/bingfa.png" alt="avatar"></p>
<h1 id="单任务版爬虫">单任务版爬虫</h1>
<ul>
<li>
<p>目标： 获取并打印所有城市第一页用户的详细信息</p>
<pre><code>  package main
	
  // 猜编码
  func determineEncoding(r io.Reader) encoding.Encoding {
      bytes, err := bufio.NewReader(r).Peek(1024)
      if err != nil {
          panic(err)
      }
      e, _, _ := charset.DetermineEncoding(bytes, &quot;&quot;)
      return e
  }
	
  func main() {
      resp, err := http.Get(&quot;http://www.zhenai.com/zhenghun&quot;)
      if err != nil {
          panic(err)
      }
      defer resp.Body.Close()
	
      if resp.StatusCode != http.StatusOk {
          fmt.Println(&quot;Error: status code&quot;, resp.StatusCode)
          return
      }
	
      e := determineEncoding(resp.Body)
      uft8Reader := transform.NewReader(resp.Body, e.NewDecoder())
	
      all, err := ioutil.ReadAll(utf8Reader)
      if err != nil {
          panic(err)
      }
      // fmt.Printf(&quot;%s\n&quot;, all)发现城市乱码，发现编码是gbk格式, 需要transform  
  }
</code></pre>
</li>
</ul>
<h2 id="获取城市列表">获取城市列表</h2>
<p>  我们采用正则表达式来获取信息的位置，该网页中数据都存放在css<code>$('#cityList&gt;dd&gt;a')</code>下。</p>
<h3 id="正则表达式">正则表达式</h3>
<pre><code>    package main 
	
	const text = &quot;My email is ccmouse@gmail.com&quot;
	
	func main() {
        re := regexp.MustCompile('[a-zA-Z0-9]+@[a-zA-Z0-9]+\.[a-zA-Z0-9]+')
        match := re.Findstring(text)
        fmt.Println(match)
	}
	package main 
	
	const text = `
	My email is ccmouse@gmail.com
	email is abc@def.org
	email2 is    kkk@qq.com
	email3 is ddd@abc.com.cn
	`
	
	func main() {
        re := regexp.MustCompile(`[a-zA-Z0-9]+@[a-zA-Z0-9.]+\.[a-zA-Z0-9]+`)
        match := re.FindAllString(text, -1)
        fmt.Println(match)
        // output
        // [ccmouse@gmail.com abc@def.org kkk@qq.com ddd@abc.com.cn]
	
        re := regexp.MustCompile(`([a-zA-Z0-9]+)@([a-zA-Z0-9]+)\(.[a-zA-Z0-9]+)`)
        match = re.FindAllStringSubmatch(text, -1)
        for _, m := range match {
            fmt.Println(m)
        }
        // output
        // [ccmouse@gmail.com ccmouse gmail .com]
        // [abc@def.org abc def .org]
        // [kkk@qq.com kkk qq .com]
        // [ddd@abc.com.cn ddd abc .com.cn]
	}
</code></pre>
<h2 id="继续">继续</h2>
<pre><code>    package main
	
	// 猜编码
	func determineEncoding(r io.Reader) encoding.Encoding {
        bytes, err := bufio.NewReader(r).Peek(1024)
        if err != nil {
            panic(err)
        }
        e, _, _ := charset.DetermineEncoding(bytes, &quot;&quot;)
        return e
	}
	
	func printCityList(contents []byte) {
        re := regexp.MustCompile(`&lt;a href=&quot;(http://www.zhenai.com/zhenghun[0-9a-z]+)&quot;[^&gt;]*&gt;([^&lt;]+)&lt;/a&gt;`)
        matches := re.FindAllSubmatch(contents, -1) // return [][][]string
        for _, m := range matches{
            fmt.Printf(&quot;City: %s, URL: %s\n&quot;, m[2], m[1])
        }
        fmt.Printf(&quot;Matches found: %d\n&quot;, len(matches))
	}
	
	func main() {
        resp, err := http.Get(&quot;http://www.zhenai.com/zhenghun&quot;)
        if err != nil {
            panic(err)
        }
        defer resp.Body.Close()
	
        if resp.StatusCode != http.StatusOk {
            fmt.Println(&quot;Error: status code&quot;, resp.StatusCode)
            return
        }
	
        e := determineEncoding(resp.Body)
        uft8Reader := transform.NewReader(resp.Body, e.NewDecoder())
	
        all, err := ioutil.ReadAll(utf8Reader)
        if err != nil {
            panic(err)
        }
        // fmt.Printf(&quot;%s\n&quot;, all)发现城市乱码，发现编码是gbk格式, 需要transform  
	}
</code></pre>
<p>  从上面的程序中已经获取到了城市列表。我们需要一些解析器来专门解析数据。</p>
<p><img src="https://cdn.jsdelivr.net/gh/facedamon/MarkDownPhotos@master/golang/parse.png" alt="avatar"></p>
<h2 id="抽象解析器">抽象解析器</h2>
<ul>
<li>输入：utf-8编码的文本</li>
<li>输出：Request{URL, 对应Parser}列表， Item列表</li>
</ul>
<h2 id="抽象架构">抽象架构</h2>
<p><img src="https://cdn.jsdelivr.net/gh/facedamon/MarkDownPhotos@master/golang/engine.png" alt="avatar"></p>
<p>  engine驱动，有一些seed种子页面，对种子进行Request包装，在上面程序中就是城市列表的url和城市列表的parser，送给engine之后，加入到任务队列，取出任务之后，将任务的URL送给Fetcher，Fetcher就是一个从网络上获取数据的模块，Fetcher返回text文本给engine，engine给Parser，返回request和item列表，这些requests就是我们将来要做的任务，那么就把他们加入任务队列。目前来说item列表，只是打印操作。</p>
<p>  上面代码中func main里面其实是Fetcher所做的事情，我们把它们摘出来。</p>
<pre><code>    // fetcher.go
	package fetcher
	
	// 猜编码
	func determineEncoding(r io.Reader) encoding.Encoding {
        bytes, err := bufio.NewReader(r).Peek(1024)
        if err != nil {
            log.Printf(&quot;fetcher error: %v&quot;, err)
            return unicode.UTF8
        }
        e, _, _ := charset.DetermineEncoding(bytes, &quot;&quot;)
        return e
	}
	
	func Fetch(url string) ([]byte, error) {
       resp, err := http.Get(url)
        if err != nil {
            panic(err)
        }
        defer resp.Body.Close()
	
        if resp.StatusCode != http.StatusOk {
            return nil, 
                fmt.Errorf(&quot;wrong status code: %d&quot;, resp.StatusCode)
        }
	
        e := determineEncoding(resp.Body)
        uft8Reader := transform.NewReader(resp.Body, e.NewDecoder())
	
        return ioutil.ReadAll(utf8Reader)
	}
</code></pre>
<p>  接下来隔离parser和engine</p>
<pre><code>    // engine/types.go
	package engine
	
	type Request struct {
        Url         string
        ParserFunc  func([]byte) ParseResult
	}
	
	type ParseResult struct {
        Requests    []Request
        Items       []interface{}
	}
	
	func NilParser([]byte) ParseResult {
        return ParseResult{}
	}

	// zhenai/parser/citylist.go
	package parser
	
	const cityListRe = `&lt;a href=&quot;(http://www.zhenai.com/zhenghun/[0-9a-z]+)&quot;[^&gt;]*&gt;([^&lt;]+)&lt;/a&gt;`
	
	func ParseCityList(contents []byte) engine.ParseResult{
        re := regexp.MustCompile(cityListRe)
            matches := re.FindAllSubmatch(contents, -1) // return [][][]string
	
            // 每一个URL就是一个ParseResult
            result := engine.ParseResult{}
            for _, m := range matches{
                // 城市名字
                result.Items = append(result.Items, &quot;City &quot; + string(m[2]))
                result.Requests = append(result.Requests, engine.Request{
                    Url: string(m[1]),
                    // 这里的Parser其实已经是第二层的城市解析器了
                    ParserFunc: engine.NilParser,
                })
            }
        return result
	}
</code></pre>
<p>  上面出现的NilParser,主要是起到一个临时不会运行出错的作用，因为我们还没有实现其它的Parser。</p>
<pre><code>    // engine/engine.go
	package engine
	
	func Run(seeds ...Request) {
        var requests []Request
        for _, r := range seeds {
            requests = append(requests, r)
        }
        for len(requests) &gt; 0 {
            r := requests[0]
            requests = requests[1:]
	
            log.Printf(&quot;fetching %s&quot;, r.Url)
            body, err := fetcher.Fetch(r.Url)
            if err != nil {
                log.Printf(&quot;Fetcher: error fetching url %s: %v&quot;, r.Url, err)
                continue
            }
	
            // 开始解析
            parseResult := r.ParserFunc(body)
            // 加入队列
            resuests = append(requests, parseResult.Requests...) 
	
            for _, item := range parseResult.Items {
                log.Printf(&quot;got item %v&quot;, item)
            }
	        
        }
	}
	package main
	
	func main() {
        engine.Run(engine.Request{
            Url:        &quot;http://www.zhenai.com/zhenghun&quot;,
            ParserFunc: parser.ParseCityList,
        })
	}
</code></pre>
<p>  我们看到main现在已经很简洁了，Run启动后的流程和图片中的抽象架构图一致。养成一个好习惯，编写测试案例，我们来测试一下parsecitylist。</p>
<pre><code>    // zhenai/parser/citylist_test.go
	package parser
	
	import (
        &quot;testing&quot;
	)
	
	func TestParseCityList(t *testing.T) {
        /*
            contents, err := fetcher.Fetch(
                &quot;http://www.zhenai.com/zhenghun&quot;
            )
            if err != nil {
                panic(err)
            }
            fmt.Printf(&quot;%s\n&quot;, contens)
            我们发现，打印下来的html文件头部少了一些符号。
            猜测一下，是哪里除了问题？
            回顾一下我们编写的猜测byte编码的程序，我们使用Reader peek了1024字节
            应该就是这1024字节不见了。为什么呢？
            bufio.NewReader(r).Peek(1024) 
            bufio对r的1024字节读取后存了起来，下次读的时候从1025开始读，这就是bufio的作用。
            既然如此，那我们就不传Reader对象了，直接传bufio.Reader，这样就算读了1024字节bufio自身不会变
	
            func determineEncoding(r *bufio.Reader) encoding.Encoding {
                bytes, err := r.Peek(1024)
                ....
            }
	
            func Fetch(url string) ([]byte, error) {
                ....
                bodyReader := bufio.NewReader(resp.Body)
                e := determineEncoding(bodyReader)
                utf8Reader := transform.NewReader(bodyReader, e.NewDecoder())
                return ioutil.ReadAll(utf8Reader)
            }
        */
        // 将网站主页的内容提前存储在html文件中
        contents, err := ioutil.ReadFile(&quot;citylist_test_data.html&quot;)
        if err != nil {
            panic(err)
        }
	    
        result := ParseCityList(contents)
	
        const resultSize = 470
        expectedUrls := []string{
            &quot;http://www.zhenai.com/zhenghun/aba&quot;,
            &quot;http://www.zhenai.com/zhenghun/akesu&quot;,
            &quot;http://www.zhenai.com/zhenghun/alashanmeng&quot;,
        }
        expectedCities := []string {
            &quot;City 阿坝&quot;, &quot;City 阿克苏&quot;, &quot;City 阿拉善盟&quot;,
        }
	
        for i, url := range expectedUirls {
            if result.Requests[i].Url != url {
                t.Errorf(&quot;expected url #%d: %s; but was %s&quot;, i, url, result.Requests[i].Url)
            }
        }
        for i, city := range expectedCities {
            if result.Items[i].(string) != city {
                t.Errorf(&quot;expected city #%d: %s; but was %s&quot;, i, city, result.Items[i].(string))
            }
        }
	
        if len(res.Requests) != resultSize {
            t.Errorf(&quot;result should have %d requests; but had %d&quot;, resultSize, len(result.Requests))
        }
	    
        if len(res.Items) != resultSize {
            t.Errorf(&quot;result should have %d items; but had %d&quot;, resultSize, len(result.Items))
        }
	}
</code></pre>
<h2 id="城市解析器">城市解析器</h2>
<pre><code>    // zhanai/parser/city.go
	
	package parser
	
	const cityRe = `&lt;a href=&quot;(http://album.zhenai.com/u/[0-9]+)&quot;[^&gt;]*&gt;([^&lt;]+)&lt;/a&gt;`
	
	func ParseCity(contents []byte) engine.ParseResult {
        re := regexp.MustCompile(cityRe)
        matches := re.FindAllSubmatch(contents, -1)
	
        result := engine.ParseResult{}
        for _, m := range matches {
            result.Items = append(result.Items, &quot;User &quot; + string(m2))
            result.Requests = append(result.Requests, engine.Request{
                Url: string(m[1]),
                ParserFunc: engine.NilParser,
            })
        }
        return result
	}
</code></pre>
<p>  这时候就可以把ParserCityList中的NilParser修改为ParseCity了
func ParseCityList(contents []byte) engine.ParseResult {
&hellip;
result.Requests = append(result.Requests, engine.Request{
Url: string(m[1]),
parserFunc: ParseCity,
})
}</p>
<h2 id="用户解析器">用户解析器</h2>
<p>  用户自身的信息和择偶条件，有重复的字段，我们采用正则和css选择器来获取。</p>
<pre><code>    // model/profile.go
	
	package model
	
	type Profile struct {
        Name            string      // 姓名
        Gender          string      // 性别
        Age             int         // 年龄
        Height          int         // 身高
        Weight          int         // 体重
        Income          string      // 收入
        Marriage        string      // 婚姻状况
        Education       string      // 教育
        Occupation      string      // 职业
        Hokou           string      // 户口
        Xinzuo          string      // 星座
        House           string      // 房子
        Car             string      // 车子
	}

	// zhenai/parser/profile.go
	
	package parser
	
	// 由于正则比较多，不能每次调用func去编译，比较耗时，这里直接先编译
	var ageRe = regexp.MustCompile(`&lt;td&gt;&lt;span class=&quot;label&quot;&gt;年龄: &lt;/span&gt;([\d]+)岁&lt;/td&gt;`)
	var heightRe = regexp.MustCompile(`&lt;td&gt;&lt;span class=&quot;label&quot;&gt;身高: &lt;/span&gt;(\d+)CM&lt;/td&gt;`)
	var incomeRe = regexp.MustCompile(`&lt;td&gt;&lt;span class=&quot;label&quot;&gt;月收入: &lt;/span&gt;([^&lt;]+)&lt;/td&gt;`)
	var weightRe = regexp.MustCompile(`&lt;td&gt;&lt;span class=&quot;label&quot;&gt;体重: &lt;/span&gt;&lt;span field=&quot;&quot;&gt;`)
	var marriageRe = regexp.MustCompile(`&lt;td&gt;&lt;span class=&quot;label&quot;&gt;婚况: &lt;/span&gt;([^&lt;]+)&lt;/td&gt;`)
	
	// 这里为什么要加name呢，是因为在parsecity中已经获取了name，就没必要再获取了
	// 这里加了name后，那上层的ParseCity的ParserFunc就需要函数式编程包装一下了
	func ParseProfile(contents []byte, name string) engine.ParseResult {
        // 建立人的结构model
        profile := model.Profile{}
        profile.Name = name
	
        if age, err := strconv.Atoi(extractString(contents, ageRe)); err == nil {
            profile.Age = age
        }
        if height, err = strconv.Atoi(extractString(contents, heightRe)); err == nil {
            profile.Height = height
        }
        if weight, err := strconv.Atoi(extractString(contents, weightRe)); err == nil {
            profile.Weight = weight
        }
        profile.Income = extractString(contents, incomeRe)
        profile.Gender = extractString(contents. genderRe)
        profile.Car = extractString(contents, carRe)
        profile.Education = extractString(contents, educationRe)
        profile.Hukou = extractString(contents, hukouRe)
        profile.House = extractString(contents, houseRe)
        profile.Marriage = extractString(contents, marriageRe)
        profile.Occupation = extractString(contents, occupationRe)
        profile.Xinzuo = extractString(contents, xinzuoRe)
	
        result := engine.ParseResult {
            Items :[]interface{}{profile},
        }
	
        return result
	}
	
	func extractString(contents []byte, re *regexp.Regexp) string {
        match := re.FindSubmatch(contents)
	
        if len(match) &gt;= 2 {
            return string(match[1])
        }
        return &quot;&quot;
	}
	// zhenai/parser/city.go 修改parsecity
	
	result.Requests = append(result.Requests, engine.Request{
                Url: string(m[1]),
                ParserFunc: func(c []byte) engine.ParseResult {
                    return ParseProfile(c, string(m[2]))
                },
            })
</code></pre>
<h1 id="并发版">并发版</h1>
<p>  在单任务版中速度特别慢，每个页面都要去请求然后等待它返回以后再请求下一个页面，这些动作完全是可以并发处理的。要把其中耗时最长等待实践最久的模块，当然是Fetcher模块，拿到URL后，到互联网上获得文本，这部分的时间是比较慢的，有远程的网络传输。Parser模块毕竟是对本地内存里文本的解析，这当然是快一些的。我们再看一步，这个Fetcher和Parser可以合成一个较大的模块，Fetcher的输出就是Parser的输入，完全可以把Fetcher和Parser合并起来，这个模块叫做Worker。</p>
<p><img src="https://cdn.jsdelivr.net/gh/facedamon/MarkDownPhotos@master/golang/crawl_worker.png" alt="avatar"></p>
<p>  这个Worker包含了Fetcher和Parser，还包含了一部分Engine。因为engine拿到了Fetcher的文本给了Parser。我们提取一下engine。</p>
<pre><code>    // engine/engine.go
	
	func worker(r Request) (ParseResult, error) {
        log.Printf(&quot;Fetching %s&quot;, r.Url)
        body, err := fetcher.Fetch(r.Url)
        if err != nil {
            log.Printf(&quot;Fetcher: error fetching url %s: %v&quot;, r.Url, err)
            return ParseResult{}, err
        }
        return r.ParserFunc(body), nil
	}
	
	func Run(seeds ...Request) {
        var requests []Request
        for _, r := range seeds {
            requests = append(requests, r)
        }
        for len(requests) &gt; 0 {
            r := requests[0]
            requests = requests[1:]
	
            parsrResult, err := worker(r)
            if err != nil {
                continue
            }
	
            //加入队列
            requests = append(requests, parseResult.Requests...)
	
            for _, item := range parseResult.Items {
                log.Printf(&quot;got item %v&quot;, item)
            }
        }
	}
</code></pre>
<h2 id="并发结构">并发结构</h2>
<p><img src="https://cdn.jsdelivr.net/gh/facedamon/MarkDownPhotos@master/golang/crawl_worker_bingfa.png" alt="avatar"></p>
<p>  我们要并发worker，然后engine不动，加入了scheduler模块，因为要面临一个多对多并发目录的分配，有很多的Request，有很多的Worker等待要执行的Request，所以这个scheduler来分配这些任务。首先Worker的输入是Request输出是Requests，Items，上面的代码已经改好了。接下来engine接收之后，打印Items，把Request分给Scheduler。单任务结构图的箭头代表函数的输入输出参数，并发版的箭头就变成了channel.每个方框代表一个goroutine。那目前最核心的事情就是scheduler。</p>
<p><img src="https://cdn.jsdelivr.net/gh/facedamon/MarkDownPhotos@master/golang/crawl_worker_1.png" alt="avatar"></p>
<p>  scheduler最简单的做法：所有Worker公用一个channel，所有的Worker都是在同一时间抢同一个request，做完了继续抢下一个。</p>
<p>  接下来我们把之前的engine修改为simpleengine，这样做的目的是将来实现的concurrentengine可以来回的切换。并且修改main.go</p>
<pre><code>    $ mv engine.go simple.go
	
	// engine/simple.go
	
	type SimpleEngine struct{}
	
	func worker(r Request) (ParseResult, error) {
        log.Printf(&quot;Fetching %s&quot;, r.Url)
        body, err := fetcher.Fetch(r.Url)
        if err != nil {
            log.Printf(&quot;Fetcher: error fetching url %s: %v&quot;, r.Url, err)
            return ParseResult{}, err
        }
        return r.ParserFunc(body), nil
	}
	
	func (e SimpleEngine)Run(seeds ...Request) {
        var requests []Request
        for _, r := range seeds {
            requests = append(requests, r)
        }
        for len(requests) &gt; 0 {
            r := requests[0]
            requests = requests[1:]
	
            parsrResult, err := worker(r)
            if err != nil {
                continue
            }
	
            //加入队列
            requests = append(requests, parseResult.Requests...)
	
            for _, item := range parseResult.Items {
                log.Printf(&quot;got item %v&quot;, item)
            }
        }
	}
	
	package main
	
	func main(){
        // 这里将来可以切换ConcurrentEngine
        engine.SimpleEngine{}.Run(engine.Request{
            Url:    &quot;http://www.zhenai.com/zhenghun&quot;,
            ParserFunc: parser.ParseCityList,
        })
	}
</code></pre>
<p>  现在开始撰写ConCurrentEngine
// engine/concurrentEngine.go</p>
<pre><code>    package engine
	
	// ConcurrentEngine本身就是一个scheduler，里面的参数给外面的scheduler设置
	type ConcurrentEngine struct {
        Scheduler Schedler
        WorkerCount int
	}
	
	// Scheduler 是一个接口，可以有很多实现
	type Scheduler interface {
        // 提交给worker的操作
        Submit(Request)
        // 这就是work chan 送给worker的任务
        ConfigureMasterWorkerChan(chan Request)
	}
	
	func (e *ConcurrentEngine) Run(seeds ...Request) {
        // 所有的worker公用一个输入输出
        in := make(chan Request)
        out := make(chan ParseResult)
        // 设置scheduler的输出，也就是worker的输入
        e.Scheduler.ConfigureMasterWorkerChan(in)
	
        // 开始建worker
        for i := 0； i &lt; e.WorkerCount; i++ {
            createWorker(in, out)
        }
        // 创建完之后，再submit给worker chan
        for _, r := range seeds {
            e.Scheduler.Submit(r)
        }
	
        // 收out
        for {
            result := &lt;- out
            for _, item := range result.Items {
                log.Printf(&quot;Got item: %v&quot;, item)
            }
            // 把下一批Request送给scheduler装载
            for _, request := range result.Requests {
                e.Scheduler.Submit(request)
            }
        }
	}
	
	func createWorker(in chan Request, out chan ParseResult) {
        // 从work chan中抢request
        // 执行完后还给work chan out
        go func(){
            for {
                request := &lt;- in
                result, err := worker(request)
                if err != nil {
                    continue
                }
                out &lt;- result
            }
        }()
	}

	// scheduler/simple.go
	
	package scheduler
	
	type SimpleScheduler struct {
        // 这其实就是ConfigureMasterChan
        workerChan chan engine.Request
	}
	
	func (s *SimpleSchedluer) Submit(r engine.Request) {
        // 把request送给work chan
        s.workerChan &lt;- r
	}
	
	func (s *SimpleScheduler) ConfigureMasterWorkerChan(c chan engine.Request) {
        s.workerChan = c
	}

	package main
	
	func main() {
        e := engine.ConCurrentEngine{
            Scheduler: &amp;engine.SimpleScheduler{},
            WorkerCount: 10,
        }
        e.Run(engine.Request{
            Url: &quot;http://www.zhenai.com/zhenghun&quot;,
            ParserFunc: ParseCityList,
        })
	}
</code></pre>
<p>  运行之后，发现程序卡在了10条数据之后。我们回顾一下</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">facedamon</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2020-03-06
        
    </span>
  </p>
  <p class="copyright-item">
      <span class="item-title">原始文档</span>
      <span class="item-content"><a class="link-to-markdown" href="http://facedamon.github.io/post/golang/base/11.%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/index.md" target="_blank">查看本文 Markdown 版本 »</a></span>
    </p>
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content"><a rel="license noopener" href="https://www.gnu.org/licenses/gpl-3.0.html" target="_self"><img src="https://img.shields.io/badge/license-GPL-blue.svg?style=flat-square)"></img></a></span>
  </p>
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/golang/">golang</a>
          <a href="/tags/%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD/">未完待续</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/books/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1/1.-%E5%BE%AE%E6%9C%8D%E5%8A%A1/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">[微服务设计(一) | 微服务]</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/golang/base/10.%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/">
            <span class="next-text nav-default">[golang base(十) | 广度优先搜索]</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:facedamon@163.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/facedamon" class="iconfont icon-github" title="github"></a>
  <a href="http://facedamon.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2019 - 
    2021
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">FaceDamon</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script><script></script><script src="https://cdn.jsdelivr.net/npm/raphael@2.2.7/raphael.min.js" integrity="sha256-67By+NpOtm9ka1R6xpUefeGOY8kWWHHRAKlvaTJ7ONI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/flowchart.js@1.8.0/release/flowchart.min.js" integrity="sha256-zNGWjubXoY6rb5MnmpBNefO0RgoVYfle9p0tvOQM+6k=" crossorigin="anonymous"></script><script></script><script src="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.js" integrity="sha256-4O4pS1SH31ZqrSO2A/2QJTVjTPqVe+jnYgOWUVr7EEc=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/snapsvg@0.5.1/dist/snap.svg-min.js" integrity="sha256-oI+elz+sIm+jpn8F/qEspKoKveTc5uKeFHNNVexe6d8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/underscore@1.8.3/underscore-min.js" integrity="sha256-obZACiHd7gkOk9iIL/pimWMTJ4W/pBsKu+oZnSeBIek=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/gh/bramp/js-sequence-diagrams@2.0.1/dist/sequence-diagram-min.js" integrity="sha384-8748Vn52gHJYJI0XEuPB2QlPVNUkJlJn9tHqKec6J3q2r9l8fvRxrgn/E5ZHV0sP" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/bramp/js-sequence-diagrams@2.0.1/dist/sequence-diagram-min.css" integrity="sha384-6QbLKJMz5dS3adWSeINZe74uSydBGFbnzaAYmp+tKyq60S7H2p6V7g1TysM5lAaF" crossorigin="anonymous">

<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: {equationNumbers: {autoNumber: "AMS"}},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"  integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>








</body>
</html>
